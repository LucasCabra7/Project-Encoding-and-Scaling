<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=66CDAA&height=120&section=header"/>

# Encoding e Scaling

Projeto desenvolvido para a disciplina de **Ci√™ncias de Dados**, utilizando a linguagem **Python** e os princ√≠pios fundamentais de **Normaliza√ß√£o/padroniza√ß√£o, treino e teste e modelos preditivos.**.

---

## üéØ Objetivos do Projeto

O objetivo deste estudo √© explorar o impacto da codifica√ß√£o de vari√°veis categ√≥ricas e das t√©cnicas de normaliza√ß√£o/padroniza√ß√£o no desempenho do algoritmo KNN (K-Nearest Neighbors).

Para isso, foi utilizado o conjunto de dados dispon√≠vel em OpenML - Dataset ID 37
Inicialmente, foram aplicadas diferentes t√©cnicas de codifica√ß√£o de vari√°veis categ√≥ricas nas colunas nominais do dataset, incluindo:
- One-Hot Encoding
- Dummy Coding
- Effect Coding

Em seguida, os dados foram transformados utilizando distintas t√©cnicas de normaliza√ß√£o e padroniza√ß√£o, tais como:
- StandardScaler
- Min-Max Scaler
- MaxAbs Scaler
- Robust Scaler
- QuantileTransformer (distribui√ß√µes uniforme e normal)

Ap√≥s o pr√©-processamento, o conjunto de dados foi dividido em 70% para treino e 30% para teste por meio da fun√ß√£o train_test_split.
O modelo KNN foi treinado e avaliado em cada cen√°rio utilizando o valor padr√£o de K = 5 (n_neighbors = 5), sem ajuste de hiperpar√¢metros.
As m√©tricas de avalia√ß√£o consideradas foram:
- Para modelos de Classifica√ß√£o: Acur√°cia e F1-Score
- Para modelos de Regress√£o: MAE (Mean Absolute Error) e RMSE (Root Mean Squared Error)
  
Por fim, foram gerados insights anal√≠ticos para interpretar o comportamento do KNN frente √†s diferentes estrat√©gias de codifica√ß√£o e normaliza√ß√£o, destacando como cada t√©cnica influencia o desempenho do modelo.

---

## üë®‚Äçüíª Caracter√≠sticas do dataset escolhido
O dataset Diabetes √© composto predominantemente por vari√°veis quantitativas, totalizando 442 amostras. Trata-se de um problema de regress√£o, cujo objetivo √© prever uma vari√°vel alvo num√©rica que representa a progress√£o da doen√ßa um ano ap√≥s o in√≠cio do estudo.

---

##  üìã Explica√ß√£o sobre o tipo de problema (classifica√ß√£o ou regress√£o):

Para a Modelos de classifica√ß√£o, utilizando o modelo KNN (K-Nearest Neighbors), mantivemos a vari√°vel alvo ‚ÄúClass‚Äù em seu formato categ√≥rico original, avaliando o desempenho por meio das m√©tricas F1-Score e Acur√°cia. J√° para os modelos de regress√£o, utilizamos o KNN Regre cuja entrada requer vari√°veis exclusivamente num√©ricas, utilizamos como vari√°vel alvo a vers√£o codificada da Class pelo m√©todo Dummy, avaliando o desempenho por meio das m√©tricas MAE (Erro Absoluto M√©dio) e RMSE (Raiz do Erro Quadr√°tico M√©dio).


---

## üß© Descrever as colunas nominais e as codifica√ß√µes aplicadas

A √∫nica coluna nominal dispon√≠vel no dataset diabetes foi a coluna class, que nos dados representava se o teste era positivo ou negativo. Utilizando One-Hot coding criamos duas tabelas e acrescentamos no DataFrame sendo uma tabela para testes positivos  e outra para testes negativos, de forma bin√°ria 1 ou 0. O problema √© que aumentamos a cardinalidade do DataFrame, o que pode criar problemas, pois pode surgir uma falsa ordena√ß√£o ou classifica√ß√£o entre categorias. Para o Dummy coding, foi utilizada a mesma analogia, mas para uma cria√ß√£o de N-1 tabelas bin√°rias, fazendo com que n√£o aumente tanto a cardinalidade. J√° para o Effect coding, tem a mesma ideia do Dummy coding, mas o grupo de compara√ß√£o assume o valor -1. No projeto em geral, testei todos os Encoding para cada Scaling, mas no final para n√£o deixar o projeto grande o suficiente, optei por deixar o Encoding Dummy nos modelos de Regress√£o, por ter sido o melhor em todas as compara√ß√µes de Encoding. 


### üß† Classifica√ß√£o - Acur√°cia:

| Encoding         | Scaling                                           | Acur√°cia - KNN                            |
|------------------|----------------------------------------------------------------|---------------------------------------|
| **One-Hot**       | **Standard**                   | 0.66   |
| **Dummy**  | **Min-Max**                          | 0.68   |
| **Effect**| **Roubst**              | 0.70|
| **Dummy**     | **MaxAbs Scaler**        | 0.68 |

---

### üß† Classifica√ß√£o - F1-SCORE:

| Encoding         | Scaling                                           | F1- Score - KNN                            |
|------------------|----------------------------------------------------------------|---------------------------------------|
| **One-Hot**       | **Standard**                   | 0.4689   |
| **Dummy**  | **Min-Max**                          | 0.496  |
| **Effect**| **Roubst**              | 0.53|
| **Dummy**     | **MaxAbs Scaler**        | 0.52 |
---

### üß† Regress√£o - MAE (Erro Absoluto M√©dio):

| Encoding         | Scaling                                           | F1- Score - KNN                            |
|------------------|----------------------------------------------------------------|---------------------------------------|
| **Dummy**       | **Standard**                   | 0.347   |
| **Dummy**  | **Min-Max**                          | 0.34  |
| **Dummy**| **Roubst**              | 0.33|
| **Dummy**     | **MaxAbs Scaler**        | 0.34 |
| **Dummy**     | **Quantile - Uniforme**        | 0.33 |
| **Dummy**     | **Quantile - Normal**        | 0.3575 |
---

### üß† Regress√£o - MAE (Erro Absoluto M√©dio):

| Encoding         | Scaling                                           | F1- Score - KNN                            |
|------------------|----------------------------------------------------------------|---------------------------------------|
| **Dummy**       | **Standard**                   | 0.46   |
| **Dummy**  | **Min-Max**                          | 0.456  |
| **Dummy**| **Roubst**              | 0.45|
| **Dummy**     | **MaxAbs Scaler**        | 0.45 |
| **Dummy**     | **Quantile - Uniforme**        | 0.43 |
| **Dummy**     | **Quantile - Normal**        | 0.458 |
---

## üìä Comparativos de desempenho do KNN - Classifica√ß√£o
<img width="1016" height="590" alt="One-hot" src="https://github.com/user-attachments/assets/b0223bec-75c2-4a83-a3cb-e761a9c4fe38" />

---

## üìä Comparativos de desempenho do KNN - Regress√£o
<img width="989" height="590" alt="regress√£o" src="https://github.com/user-attachments/assets/64658992-0035-4df1-9d06-66fd985e7f96" />

---

## Equipe do Projeto

<div align="center">
  <table>
    <tr>
      <td align="center">
        <img src="https://avatars.githubusercontent.com/u/155683708?v=4" width="100px" alt="Lucas Cabral"/><br/>
        <b>Lucas Cabral</b>
      </td>
    </tr>
  </table>
</div>

---

<p align="center">
  &copy; 2025 Universidade Federal de Pernambuco - Centro de Inform√°tica. Todos os direitos reservados.
</p>

<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=66CDAA&height=120&section=header"/>
